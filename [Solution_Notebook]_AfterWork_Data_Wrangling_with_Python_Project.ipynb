{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lilian-2021/DS/blob/main/%5BSolution_Notebook%5D_AfterWork_Data_Wrangling_with_Python_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1HW8GjoS7AN"
      },
      "source": [
        "# AfterWork: Data Wrangling with Python Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLG2VTrnTvYL"
      },
      "source": [
        "## 1. Defining the Question"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XecOwPNorl2W"
      },
      "source": [
        "### a) Specifying the Data Analysis Question"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZykmRrbGd13"
      },
      "source": [
        "Specify the reasearch question that you'll be answering."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ym7-i7auXZPg"
      },
      "source": [
        "> i.e. Which was the most improved country year 2017 - 2018 as per the GDP ranking?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4wfHZwQrs-t"
      },
      "source": [
        "### b) Defining the Metric for Success"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuQcoaLFGjkH"
      },
      "source": [
        "How will you know that your solution will have satisfied your research question?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9BPYqunry97"
      },
      "source": [
        "### c) Understanding the context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jeqV9VPG1tg"
      },
      "source": [
        "Provide some background information...."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KMRBJ7zr9HD"
      },
      "source": [
        "### d) Recording the Experimental Design"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YG0dB0_PG5_i"
      },
      "source": [
        "Describe the steps/approach that you will use to answer the given question."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSGyg6kWsBUl"
      },
      "source": [
        "### e) Data Relevance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UogUWzkTHJ9D"
      },
      "source": [
        "How relevant was the provided data?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUNbvIvnT7ep"
      },
      "source": [
        "## 2. Reading the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STUSuuyTTBgx"
      },
      "source": [
        "# Importing our libraries\n",
        "# ---\n",
        "#\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJn2KjW-WMlG"
      },
      "source": [
        "# Load the data below\n",
        "# ---\n",
        "# Dataset url = https://bit.ly/BusBreakdownDataset\n",
        "# ---\n",
        "#\n",
        "df = pd.read_csv('https://bit.ly/BusBreakdownDataset')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7168_y8EhZg7"
      },
      "source": [
        "# Checking the first 5 rows of data\n",
        "# ---\n",
        "#\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87pOSl5MhcdL"
      },
      "source": [
        "# Checking the last 5 rows of data\n",
        "# ---\n",
        "#\n",
        "df.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8yvg3qQl_HF"
      },
      "source": [
        "# Sample 10 rows of data\n",
        "# ---\n",
        "#\n",
        "df.sample(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3sfP6y2hgIS"
      },
      "source": [
        "# Checking number of rows and columns\n",
        "# ---\n",
        "#\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AovarG6Bhk4y"
      },
      "source": [
        "# Checking datatypes\n",
        "# ---\n",
        "#\n",
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKNcQTasmCgA"
      },
      "source": [
        "Record your observations below:\n",
        "* It is a pretty large dataset with 21 variables.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckfufNrcUHeH"
      },
      "source": [
        "## 3. External Data Source Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6L4sl_0WXlbg"
      },
      "source": [
        "You can make sure your data matches other credible information. This ensures that the measurements are roughly in line with what they should be and it serves as a check on what other things might be wrong in your dataset.\n",
        "\n",
        "External validation can often be as simple as checking your data against some other data i.e. country population your dataset with country population on world bank data.\n",
        "\n",
        "Replace the text found on this text cell with your external data source validation information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlBMxEDBUc9B"
      },
      "source": [
        "## 4. Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNtWOlYAkcO_"
      },
      "source": [
        "### Performing Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYxrLT0GiQSc"
      },
      "source": [
        "# Checking datatypes and missing entries of all the variables\n",
        "# ---\n",
        "#\n",
        "df.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSgG917YmgbK"
      },
      "source": [
        "We observe the following from our dataset:\n",
        "\n",
        "*   Some variables like `Run_Type`, `Bus_No`, `Route_Number`, `Reason`, and `Schools_Serviced` have a few missing values while others such as `Boro`, `How_Long_Delayed`, and `Incident_Number` have very significant data loss.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydiwcHbkHSMt"
      },
      "source": [
        "# Standardizing your dataset i.e. variable renaming\n",
        "# ---\n",
        "#\n",
        "df.columns = [col.lower() for col in df.columns]\n",
        "df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcfnxBJciRet"
      },
      "source": [
        "# Checking how many duplicate rows are there in the data\n",
        "# ---\n",
        "#\n",
        "df[df.duplicated()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iP8KPKImnvC"
      },
      "source": [
        "We observe the following from our dataset:\n",
        "\n",
        "*   There are no duplicated records.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwXq9B1LjlaN"
      },
      "source": [
        "# Checking if any of the columns are all null\n",
        "# ---\n",
        "#\n",
        "df.isnull().all()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqZJ1NF3mxHh"
      },
      "source": [
        "We observe the following from our dataset:\n",
        "\n",
        "*   None of the variables are all null.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsvDZHqxjrdx"
      },
      "source": [
        "# Checking if any of the rows are all null\n",
        "# ---\n",
        "#\n",
        "df.isnull().all(axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-i3KQTLnBvZ"
      },
      "source": [
        "We observe the following from our dataset:\n",
        "\n",
        "*   Observation 1\n",
        "*   Observation 2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRdCkarYiin-"
      },
      "source": [
        "# Checking if the \"Yes/No\" fields contain only these 2 values\n",
        "# for have_you_alerted_opt variable\n",
        "# ---\n",
        "# Hint: Use unique() function\n",
        "#\n",
        "df.have_you_alerted_opt.unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB335aOVnCxj"
      },
      "source": [
        "We observe the following from our dataset:\n",
        "\n",
        "*   The `have_you_alerted_opt` variable has either 'Yes' or 'No' values.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbPVfstMikvf"
      },
      "source": [
        "# Checking if the \"Yes/No\" fields contain only these 2 values\n",
        "# for has_contractor_notified_parents variable\n",
        "# ---\n",
        "#\n",
        "df.has_contractor_notified_parents.unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_YnOORcnGYw"
      },
      "source": [
        "We observe the following from our dataset:\n",
        "\n",
        "*   The `has_contractor_notified_parents` variable has either 'Yes' or 'No' values.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1b7RAbNi3xf"
      },
      "source": [
        "# Checking if the \"Yes/No\" fields contain only these 2 values\n",
        "# for has_contractor_notified_schools variable\n",
        "# ---\n",
        "#\n",
        "df.has_contractor_notified_schools.unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moY8-oqAjt7k"
      },
      "source": [
        "# Checking unique values in breakdown_or_running_late variable to ensure there is no duplication\n",
        "# ---\n",
        "#\n",
        "df.breakdown_or_running_late.unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICemYiD1kQTK"
      },
      "source": [
        "# Checking unique values in school_age_or_prek variable\n",
        "# ---\n",
        "#\n",
        "df.school_age_or_prek.unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geEgU4KhkUkF"
      },
      "source": [
        "# Checking unique values in school_year variable\n",
        "# ---\n",
        "#\n",
        "df.school_year.unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xo1liVO-kU6R"
      },
      "source": [
        "# Checking unique values in reason variable\n",
        "# ---\n",
        "#\n",
        "df.reason.unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_g8UMAtkWRO"
      },
      "source": [
        "# Checking unique values in run_type variable\n",
        "# ---\n",
        "#\n",
        "df.run_type.unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwmxKhGmkYNK"
      },
      "source": [
        "# Checking unique values in boro variable\n",
        "# ---\n",
        "#\n",
        "df.boro.unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8b_wULuodN8"
      },
      "source": [
        "### Overall Data Cleaning Observations\n",
        "**Missing Values**\n",
        "\n",
        "- There are a large number of missing values in the fields \"How_Long_Delayed\" which is important to our analysis.\n",
        "- There is an extremely large number of missing values in the \"Incident_number\" field but this is not incidental to our analysis and cannot be filled in without additional information.\n",
        "\n",
        "**Error in values**\n",
        "\n",
        "- \"How_Long_Delayed\" contains string values such as \"MINS\" or \"mins\" and a range of values, which needs to be changed to single integer value for our analysis.\n",
        "\n",
        "**Error in Datatypes**\n",
        "\n",
        "- \"How_Long_Delayed\" is a string datatype, should be converted to integer type.\n",
        "\n",
        "**Error in field names**\n",
        "- The column name \"Boro\" should be renamed to \"Borough\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUXeWCRuprIp"
      },
      "source": [
        "### Next Steps: Data Cleaning Steps\n",
        "\n",
        "**Error in values**\n",
        "\n",
        "- Extract the first integer value (lowest delay time) in the column \"How_Long_Delayed\"\n",
        "\n",
        "\n",
        "**Missing Values**\n",
        "\n",
        "- Impute the missing values in the field \"How_Long_Delayed\" with the mean value.\n",
        "\n",
        "\n",
        "**Error in Datatypes**\n",
        "\n",
        "- Convert \"How_Long_Delayed\" to int datatype.\n",
        "\n",
        "\n",
        "\n",
        "**Error in field names**\n",
        "\n",
        "- Rename the column \"Boro\" to \"Borough\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27EznvNypkVb"
      },
      "source": [
        "# Lets first start by creating a copy of our dataframe\n",
        "# df_clean = df.copy(). We will use this copy as our cleaning copy.\n",
        "# ---\n",
        "#\n",
        "df_clean = df.copy()\n",
        "df_clean.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlfP46wxqGIb"
      },
      "source": [
        "# Then extracting the lowest delay time in the column how_long_delayed from the string\n",
        "#\n",
        "df_clean['how_long_delayed'] = df_clean['how_long_delayed'].str.extract('(\\d+)')\n",
        "df_clean['how_long_delayed'].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TCaPQwzqZwx"
      },
      "source": [
        "We impute the null values in 'how_long_delayed' column with mean of the column. This will take a couple of steps..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jk49oxooqOLB"
      },
      "source": [
        "# We first convert our how_long_delayed to float type to allow for imputation\n",
        "# ---\n",
        "#\n",
        "df_clean[\"how_long_delayed\"] = df_clean[\"how_long_delayed\"].astype('float')\n",
        "df_clean[\"how_long_delayed\"].dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gkyJ9frqlTP"
      },
      "source": [
        "# Then later perform our mean imputation\n",
        "# ---\n",
        "#\n",
        "df_clean[\"how_long_delayed\"] = df_clean[\"how_long_delayed\"].fillna(df_clean[\"how_long_delayed\"].mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BjIJBjdq05B"
      },
      "source": [
        "# Then convert back our how_long_delayed column to integer datatype\n",
        "# ---\n",
        "#\n",
        "df_clean[\"how_long_delayed\"] = df_clean[\"how_long_delayed\"].astype('int')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PL3Mx2GjrDhD"
      },
      "source": [
        "# Then check for nulls in the column\n",
        "# ---\n",
        "#\n",
        "df_clean[\"how_long_delayed\"].isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8s5E8v6rJzX"
      },
      "source": [
        "# Rename Boro column to Borough\n",
        "# ---\n",
        "#\n",
        "df_clean = df_clean.rename(columns={'Boro': 'Borough'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbYznrWJ2BC1"
      },
      "source": [
        "# Lastly we convert all values in our columns to lower case\n",
        "# for ease of reading\n",
        "# ---\n",
        "#\n",
        "df_clean = df_clean.applymap(lambda x: x.lower() if isinstance(x, str) else x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fe3IzcDyrS_6"
      },
      "source": [
        "# Check the first 5 record the cleaned dataset\n",
        "# ---\n",
        "#\n",
        "df_clean.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTbdjSrhVIiT"
      },
      "source": [
        "\n",
        "## 5. Solution Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdHyc8WYHlAG"
      },
      "source": [
        "Here we investigate the questions that would help craft our recommendations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nh5mcts5IK8U"
      },
      "source": [
        "### 5.a) Questions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Q6JR-4yfVHf"
      },
      "source": [
        "# 1. Which bus companies that had the highest breakdowns?\n",
        "# ---\n",
        "#\n",
        "breakdowns = df_clean.groupby('bus_company_name')['busbreakdown_id'].count()\n",
        "\n",
        "# Sort to get bus company with highest breakdowns\n",
        "# ---\n",
        "# YOUR CODE GOES BELOW\n",
        "#\n",
        "\n",
        "company_with_highest_breakdowns = breakdowns.idxmax()\n",
        "highest_breakdown_count = breakdowns.max()\n",
        "\n",
        "print(f\"The bus company with the highest number of breakdowns is '{company_with_highest_breakdowns}' with {highest_breakdown_count} breakdowns.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYtdLdxHfVrh"
      },
      "source": [
        "# 2. What were the top 3 reasons for bus delays?\n",
        "# ---\n",
        "#\n",
        "bus_delay = df_clean.groupby(['reason']).count()[['how_long_delayed']].reset_index()\n",
        "\n",
        "# Sort to get the most frequent reason\n",
        "# ---\n",
        "# YOUR CODE GOES BELOW\n",
        "#\n",
        "bus_delay.sort_values(by='how_long_delayed', ascending=0)[:3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aTP8trqsK3g"
      },
      "source": [
        "# 3. How many students were in the buses when they broke down?\n",
        "# ---\n",
        "#\n",
        "num_students = df_clean.groupby(['number_of_students_on_the_bus']).count()[['busbreakdown_id']].reset_index()\n",
        "num_students.sum()[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jz7jXe8BtLGw"
      },
      "source": [
        "# 4. Which were most frequent reasons for bus breakdowns?\n",
        "# ---\n",
        "#\n",
        "breakdown_reasons = df_clean[df_clean.breakdown_or_running_late == 'breakdown'].groupby(['reason']).count()\n",
        "\n",
        "# Sort to get most frequent reasons\n",
        "# ---\n",
        "# YOUR CODE GOES BELOW\n",
        "#\n",
        "breakdown_reasons.idxmax()[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKfAq-PGwhbM"
      },
      "source": [
        "# 5. What were the most frequent reasons for the bus running late?\n",
        "# ---\n",
        "#\n",
        "reasons = df_clean.groupby(['reason','how_long_delayed']).count()\n",
        "\n",
        "# Get the records with running late reasons and sort to get most frequent reasons\n",
        "# ---\n",
        "# YOUR CODE GOES BELOW\n",
        "#\n",
        "reasons.idxmax()[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwG_TiwDyvEP"
      },
      "source": [
        "# 6. What was the average delay time for each reason type?\n",
        "# ---\n",
        "#\n",
        "avg_delay = df_clean.groupby('reason').mean().reset_index()\n",
        "\n",
        "# Get the records with reasons and how long on average a delay took then sort\n",
        "# ---\n",
        "# YOUR CODE GOES BELOW\n",
        "#\n",
        "avg_delay.mean()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}