{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "FGEewV3YZusP",
        "2ybulwkqak9t",
        "sCgiGgE5czvd",
        "pCz49LoBc6-f",
        "I74PHKiXdKAI",
        "njHHgTazdeXl",
        "MVPDkTdHeBJJ",
        "UwuNrqYZeM17",
        "YCRHh9n3eka9",
        "zflVcZzZfm2i",
        "Fjs8aRgbfq_i",
        "qju4x3jagIDE",
        "V06vW7c1gIqC",
        "fR7_ryhQgIqD",
        "i12fpeMIgTrc",
        "FjbV6n-GgVy9",
        "j6y4mX8Dgbhm",
        "GYxpy3gvgbhy",
        "4pn-N_xGanEc",
        "Nkn3AC2jk_9_",
        "LIjTZQ7Nl1Ya",
        "MLbBcOz7ZyGf",
        "Hx7-IW4ras6M",
        "l7OfBGJ3qInw",
        "hkeKN9TnmiYi",
        "ttRP43jcmiYj",
        "c0ZavMQampu2",
        "NFkLHoyCmtWI",
        "9iXmmYcimtWU",
        "BZBbmO4NmyXJ",
        "4KCjOt51myXV",
        "pHO2Bh6qauQ3",
        "BbayVloVswGR",
        "BOGL5JQUswGy",
        "mAmlMPf2Z0wj",
        "I68qM-lFa0J7",
        "ym_QIjzY-HX5",
        "-7UhaqNF-peI",
        "NIHL_Zo__Bdk",
        "yMpFRP8m_Bdx",
        "C74nBKlL_Bx6",
        "F_y4ty53_Bx8",
        "6vCykE4o_B-P",
        "8QpAV73G_B-Q",
        "EMFGz1GtAcjf",
        "Ban4LNR3HwhZ",
        "Np9QNp4nZ3dy",
        "fc1zTNv_a-ti",
        "EOnALrXa5PBl",
        "irSK1qAU7FRX",
        "-9MCIESwZ7qP",
        "J6QRaamXgnUu",
        "_0DqBhKMbH6-",
        "yR9vfGGfXLnh",
        "eSsMc_WibILr"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kigunda-lilian/Data_science/blob/main/Copy_of_%5BSample_Notebook%5D_AfterWork_Moringa_Data_Science_Program_%7C_Summary_Course.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [Sample Notebook] AfterWork: Moringa Data Science Program | Summary Course"
      ],
      "metadata": {
        "id": "e4LA7NjAZsp9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Pre-work"
      ],
      "metadata": {
        "id": "FGEewV3YZusP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Python programming"
      ],
      "metadata": {
        "id": "2ybulwkqak9t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1.1 Variables and Data Types"
      ],
      "metadata": {
        "id": "sCgiGgE5czvd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variables in Python are used to store data values. Data types specify the type of data that a variable can hold, such as integers, strings, or lists. Understanding variables and data types is important because it allows us to manipulate and work with different types of data in our programs.\n",
        "\n"
      ],
      "metadata": {
        "id": "K-dAijJyc3pP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBakRp8MZfuY"
      },
      "outputs": [],
      "source": [
        "# Creating a variable 'num' and assigning an integer value 5 to it\n",
        "num = 5\n",
        "\n",
        "# Creating a variable 'name' and assigning a string value 'John' to it\n",
        "name = 'John'\n",
        "\n",
        "# Creating a variable 'my_list' and assigning a list of integers to it\n",
        "my_list = [1, 2, 3, 4, 5]\n",
        "\n",
        "# Printing the values of the variables\n",
        "print(num)\n",
        "print(name)\n",
        "print(my_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Challenge"
      ],
      "metadata": {
        "id": "pCz49LoBc6-f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a variable 'is_raining' and assign a boolean value True to it. Then, create a variable 'temperature' and assign a float value 25.5 to it. Finally, print the values of both variables."
      ],
      "metadata": {
        "id": "BEAV_t3Dc_B-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code here\n"
      ],
      "metadata": {
        "id": "ezGY72zpc8DW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1.2 Print Statements and Comments"
      ],
      "metadata": {
        "id": "I74PHKiXdKAI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print statements and comments allows us to display output to the console and add notes to our code for better understanding. Print statements are used to output text or variables to the console, while comments are used to add explanations or notes within the code without affecting the program's functionality.\n",
        "\n"
      ],
      "metadata": {
        "id": "lgCaoYMEdWJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print a greeting message to the console\n",
        "print(\"Hello, welcome to the world of Python!\")\n",
        "\n",
        "# Print a variable value to the console\n",
        "name = \"Alice\"\n",
        "print(\"The name is:\", name)\n",
        "\n",
        "# Add a comment to explain the next line of code\n",
        "# This line will print a goodbye message\n",
        "print(\"Goodbye, see you next time!\")"
      ],
      "metadata": {
        "id": "bK_LED9wdboB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Challenge"
      ],
      "metadata": {
        "id": "njHHgTazdeXl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a variable 'apples' and assign it a value representing the total number of apples in the basket. Then use a print statement to display the value of the 'apples' variable to the console.\n"
      ],
      "metadata": {
        "id": "GlEAv-yqd333"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of apples in the basket\n",
        "# Write your code here\n",
        "\n",
        "# Print the total number of apples in the basket\n",
        "# Write your code here\n"
      ],
      "metadata": {
        "id": "QGl-E5nBdnvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1.3 Arithmetic Operations"
      ],
      "metadata": {
        "id": "MVPDkTdHeBJJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performing arithmetic operations allows us to manipulate numerical values using mathematical operators. This concept is important because it enables us to perform calculations, solve mathematical problems, and manipulate data in our programs.\n",
        "\n"
      ],
      "metadata": {
        "id": "igOA2LdCeHoP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform addition operation\n",
        "result_addition = 10 + 5\n",
        "print(result_addition)\n",
        "\n",
        "# Perform subtraction operation\n",
        "result_subtraction = 10 - 5\n",
        "print(result_subtraction)\n",
        "\n",
        "# Perform multiplication operation\n",
        "result_multiplication = 10 * 5\n",
        "print(result_multiplication)\n",
        "\n",
        "# Perform division operation\n",
        "result_division = 10 / 5\n",
        "print(result_division)\n",
        "\n",
        "# Perform exponentiation operation\n",
        "result_exponentiation = 10 ** 2\n",
        "print(result_exponentiation)"
      ],
      "metadata": {
        "id": "huR61kG6eL-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Challenge"
      ],
      "metadata": {
        "id": "UwuNrqYZeM17"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform the following arithmetic operations:\n",
        "1. Add 15 and 7\n",
        "2. Subtract 5 from 12\n",
        "3. Multiply 8 by 4\n",
        "4. Divide 20 by 3\n",
        "5. Calculate the remainder when dividing 17 by 4. Use the % to calculate the remainder."
      ],
      "metadata": {
        "id": "3ZpZL1s4eSdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform addition operation\n",
        "# Write your code here\n",
        "\n",
        "\n",
        "# Perform subtraction operation\n",
        "# Write your code here\n",
        "\n",
        "\n",
        "# Perform multiplication operation\n",
        "# Write your code here\n",
        "\n",
        "\n",
        "# Perform division operation\n",
        "# Write your code here\n",
        "\n",
        "\n",
        "# Calculate remainder\n",
        "# Write your code here\n"
      ],
      "metadata": {
        "id": "TPcXgawUeOTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1.4 Type Conversion"
      ],
      "metadata": {
        "id": "YCRHh9n3eka9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Type conversion refers to the process of converting one data type into another. We can use type conversion when we need to perform operations that require data of a specific type, or when we want to ensure that our data is in the correct format. For example, we may need to convert a string to an integer in order to perform mathematical calculations."
      ],
      "metadata": {
        "id": "PqatREXuepmv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting a string to an integer\n",
        "num_str = \"10\"\n",
        "num_int = int(num_str)\n",
        "print(num_int)\n",
        "\n",
        "# Converting an integer to a float\n",
        "num_int = 5\n",
        "num_float = float(num_int)\n",
        "print(num_float)\n",
        "\n",
        "# Converting a float to a string\n",
        "num_float = 3.14\n",
        "num_str = str(num_float)\n",
        "print(num_str)"
      ],
      "metadata": {
        "id": "YDvHbazUeuYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1.5 Lists and Dictionaries"
      ],
      "metadata": {
        "id": "zflVcZzZfm2i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Working with lists and dictionaries allows us to store and manipulate collections of data. Lists are ordered collections of items, while dictionaries are unordered collections of key-value pairs. This concept is important because it allows us to efficiently store and access data in our programs.\n",
        "\n"
      ],
      "metadata": {
        "id": "s1G0V_g7gi22"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a list of numbers\n",
        "numbers = [1, 2, 3, 4, 5]\n",
        "\n",
        "# Accessing and printing the third element in the list\n",
        "print(numbers[2])\n",
        "\n",
        "# Creating a dictionary of student names and their corresponding ages\n",
        "student_ages = {'Alice': 20, 'Bob': 22, 'Charlie': 21}\n",
        "\n",
        "# Accessing and printing Bob's age from the dictionary\n",
        "print(student_ages['Bob'])"
      ],
      "metadata": {
        "id": "jUo9Y82efqiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Challenge"
      ],
      "metadata": {
        "id": "Fjs8aRgbfq_i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Create a list of fruits including 'apple', 'banana', 'orange', 'grape', and 'kiwi'. Then, create a dictionary where the keys are the fruits and the values are their corresponding colors. Finally, print out the color of the 'banana' from the dictionary.\n",
        "\n",
        "* To create a list of fruits: fruits = ['apple', 'banana', 'orange', 'grape', 'kiwi']. To create a dictionary: fruit_colors = {'apple': 'red', 'banana': 'yellow', 'orange': 'orange', 'grape': 'purple', 'kiwi': 'green'}. To print out the color of 'banana': print(fruit_colors['banana'])."
      ],
      "metadata": {
        "id": "cpl-g3t0grOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code here\n"
      ],
      "metadata": {
        "id": "6i8UhFPYf1eQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1.6 Conditional Statements"
      ],
      "metadata": {
        "id": "qju4x3jagIDE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conditional statements in Python allow us to execute different blocks of code based on whether a certain condition is true or false. This allows us to control the flow of our program and make decisions based on specific criteria.\n",
        "\n"
      ],
      "metadata": {
        "id": "NIrx2Z9yiSZs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = 10\n",
        "if x > 5:\n",
        "    print(\"x is greater than 5\")\n",
        "else:\n",
        "    print(\"x is not greater than 5\")"
      ],
      "metadata": {
        "id": "T94OuRSMgIDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1.7 For Loops"
      ],
      "metadata": {
        "id": "V06vW7c1gIqC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For loops in Python allow us to iterate over a sequence of elements, such as a list or a range of numbers. This is useful when we want to perform a certain action on each element in the sequence.\n",
        "\n"
      ],
      "metadata": {
        "id": "ozm2IEAsixmt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of using a for loop to iterate over a list of numbers\n",
        "numbers = [1, 2, 3, 4, 5]\n",
        "for num in numbers:\n",
        "    print(num)"
      ],
      "metadata": {
        "id": "ilF4auLfgIqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Challenge"
      ],
      "metadata": {
        "id": "fR7_ryhQgIqD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a list of car names and use a for loop to iterate over the list, printing out each car's name in the loop"
      ],
      "metadata": {
        "id": "g6VqL-SUi9PP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of cars\n",
        "cars = [\"Toyota\", \"Honda\", \"Ford\", \"Chevrolet\", \"BMW\"]\n",
        "\n",
        "# Write your code here\n"
      ],
      "metadata": {
        "id": "3syxco7SgIqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1.8 While Loops"
      ],
      "metadata": {
        "id": "i12fpeMIgTrc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "While loops in Python allow us to repeatedly execute a block of code as long as a specified condition is true. This is useful when we want to perform a task multiple times without having to manually write out each iteration.\n",
        "\n"
      ],
      "metadata": {
        "id": "0XhSFWB7jE-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using a while loop to print numbers from 1 to 5\n",
        "num = 1\n",
        "while num <= 5:\n",
        "    print(num)\n",
        "    num += 1 # Similar to num = num + 1"
      ],
      "metadata": {
        "id": "DzUUvUSrgTrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1.9 Defining Functions"
      ],
      "metadata": {
        "id": "FjbV6n-GgVy9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining functions involves encapsulating a set of instructions and giving it a name. This allows us to reuse code, make our code more maintainable, and improve readability. When we define a function, we are essentially creating a block of code that performs a specific task. We can then call this function whenever we need to execute that task, without having to rewrite the same code multiple times."
      ],
      "metadata": {
        "id": "jfzlei92j0OP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a simple function that prints a greeting message\n",
        "def greet():\n",
        "    print(\"Hello, welcome to our program!\")\n",
        "\n",
        "# Call the function to display the greeting message\n",
        "greet()"
      ],
      "metadata": {
        "id": "4uRjRA-XgV0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1.10 Returning Values from Functions"
      ],
      "metadata": {
        "id": "j6y4mX8Dgbhm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Returning values from functions involves getting output from a function and using it in our code. When we want a function to perform a specific task and return a result, we use the concept of returning values."
      ],
      "metadata": {
        "id": "svbxukjIkJjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_area_of_circle(radius):\n",
        "    area = 3.14 * radius * radius\n",
        "    return area\n",
        "\n",
        "radius = 5\n",
        "circle_area = calculate_area_of_circle(radius)\n",
        "print(\"The area of the circle with radius\", radius, \"is:\", circle_area)"
      ],
      "metadata": {
        "id": "JLXVvGYNgbhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Challenge"
      ],
      "metadata": {
        "id": "GYxpy3gvgbhy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a function called 'calculate_total_cost' that takes in the quantity and price of an item as parameters. The function should calculate the total cost by multiplying the quantity and price, and return the result. Use this function to calculate the total cost of 3 items priced at $10 each."
      ],
      "metadata": {
        "id": "8xeHeIJMkPPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code here\n",
        "\n",
        "\n",
        "quantity = 3\n",
        "price = 10\n",
        "total_cost = calculate_total_cost(quantity, price)\n",
        "print(\"The total cost of\", quantity, \"items priced at $\", price, \"each is:\", total_cost)"
      ],
      "metadata": {
        "id": "DENE5KCjgbhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Data collection"
      ],
      "metadata": {
        "id": "4pn-N_xGanEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Pandas library for data manipulation\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "1m3vE9NCl8EV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2.1 Importing Data From a CSV file"
      ],
      "metadata": {
        "id": "Nkn3AC2jk_9_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the dataset\n",
        "df = pd.read_csv(\"https://afterwork.ai/ds/e/healthcare_and_pharmaceuticals_fah6v.csv\")\n",
        "\n",
        "# Preview the dataset\n",
        "df.head()"
      ],
      "metadata": {
        "id": "RcWb2CoOaqSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Challenge"
      ],
      "metadata": {
        "id": "LIjTZQ7Nl1Ya"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read the CSV file from the following URL: https://afterwork.ai/ds/ch/healthcare_and_pharmaceuticals_stnf5.csv and create a Pandas DataFrame. Remember to use the Pandas library to read the CSV file and display the first few rows of the DataFrame to ensure it was read correctly."
      ],
      "metadata": {
        "id": "UQLLjQkvmOFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code here\n"
      ],
      "metadata": {
        "id": "dg0HXrEzl2dK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Data Analysis & Engineering"
      ],
      "metadata": {
        "id": "MLbBcOz7ZyGf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Introduction to Pandas"
      ],
      "metadata": {
        "id": "Hx7-IW4ras6M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.1 Data Cleaning"
      ],
      "metadata": {
        "id": "l7OfBGJ3qInw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data cleaning is the process of identifying and correcting errors or inconsistencies in a dataset to improve its quality. We clean data to ensure accuracy and reliability in our analysis. We can use data cleaning when we have missing values, outliers, or incorrect data entries in our dataset. For example, we may have a dataset with missing values in certain columns. To clean this data, we can fill in the missing values with the mean or median of the column."
      ],
      "metadata": {
        "id": "RwK-_6bVqV8o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv(\"https://afterwork.ai/ds/e/healthcare_and_pharmaceuticals_368ti.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "pr1HBB_eqIny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "print(\"Missing values before data cleaning:\")\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "JG9wV-aUqb68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove rows with missing values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Replace incorrect values in 'Dosage' column\n",
        "df['Dosage'] = df['Dosage'].str.replace('2 puffs as needed', '2 puffs')"
      ],
      "metadata": {
        "id": "M_uVLY1MqaAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "print(\"Missing values after data cleaning:\")\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "eyg4DK3Aq96c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.2 Selecting Columns"
      ],
      "metadata": {
        "id": "hkeKN9TnmiYi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selecting columns allows us to extract specific columns from a dataset that has been imported into a Pandas DataFrame. This concept is important because it helps us focus on only the relevant data columns for our analysis, making our code more efficient and easier to work with."
      ],
      "metadata": {
        "id": "d2eGq6M5q0y9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset into a Pandas DataFrame\n",
        "df = pd.read_csv(\"https://afterwork.ai/ds/e/healthcare_esm0o.csv\")\n",
        "\n",
        "# Preview the dataset\n",
        "df.head()"
      ],
      "metadata": {
        "id": "POwuTZOYmiYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select specific columns 'Name', 'Age', and 'Diagnosis'\n",
        "selected_columns = df[['Name', 'Age', 'Diagnosis']]\n",
        "\n",
        "# Preview the selected columns\n",
        "selected_columns.head()"
      ],
      "metadata": {
        "id": "YJym9ovCrLaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Challenge"
      ],
      "metadata": {
        "id": "ttRP43jcmiYj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Select the 'Name' and 'Age' columns from the dataset located at https://afterwork.ai/ds/ch/healthcare_zg1dt.csv using Pandas. Remember to use the read_csv() function to import the dataset into a DataFrame first.\n"
      ],
      "metadata": {
        "id": "K3FSJI66rS-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code here\n"
      ],
      "metadata": {
        "id": "y65WdP56miYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.3 Filtering Records"
      ],
      "metadata": {
        "id": "c0ZavMQampu2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filtering records allows us to extract specific rows or columns from a dataset that meet certain criteria. This is important for analyzing and visualizing only the relevant data that we are interested in.\n",
        "\n"
      ],
      "metadata": {
        "id": "x68pXY0xrayd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv(\"https://afterwork.ai/ds/e/healthcare_vq8e5.csv\")\n",
        "\n",
        "# Preview the dataset\n",
        "df.head()"
      ],
      "metadata": {
        "id": "e_kd_QBrmpvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter records based on Age greater than 40\n",
        "filtered_df = df[df['Age'] > 40]\n",
        "\n",
        "# Display the filtered records\n",
        "filtered_df"
      ],
      "metadata": {
        "id": "0RvS0X4erhg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.4 Sorting"
      ],
      "metadata": {
        "id": "NFkLHoyCmtWI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sorting dataframes allows us to arrange the rows of our dataset in a specific order based on the values of one or more columns. This is important because it helps us to better understand our data, identify patterns, and make informed decisions based on the sorted data.\n",
        "\n"
      ],
      "metadata": {
        "id": "tLosTFBPr3uW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv(\"https://afterwork.ai/ds/e/healthcare_x6c9g.csv\")\n",
        "\n",
        "# Preview the dataset\n",
        "df.head()"
      ],
      "metadata": {
        "id": "wybS7JbJmtWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort the dataframe by Age in descending order\n",
        "df_sorted = df.sort_values(by='Age', ascending=False)\n",
        "\n",
        "# Preview the sorted dataframe\n",
        "df_sorted.head()"
      ],
      "metadata": {
        "id": "IMQ8lTS5r7L6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Challenge"
      ],
      "metadata": {
        "id": "9iXmmYcimtWU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sort the given healthcare dataset by the 'Income' column in ascending order. Use the dataset from the URL: https://afterwork.ai/ds/ch/healthcare_6jutf.csv"
      ],
      "metadata": {
        "id": "n2mkwuHJsA4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv(\"https://afterwork.ai/ds/ch/healthcare_6jutf.csv\")\n",
        "\n",
        "# Sort the dataframe by Income in ascending order\n",
        "# Write your code here\n",
        "\n",
        "# Preview the sorted dataframe\n",
        "# Write your code here\n"
      ],
      "metadata": {
        "id": "_1g3gcmUmtWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.5 Grouping"
      ],
      "metadata": {
        "id": "BZBbmO4NmyXJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grouping allows us to organize and analyze data based on specific criteria. This concept involves grouping data together based on a common attribute or value, and then performing operations on each group.\n",
        "\n"
      ],
      "metadata": {
        "id": "ryTWWlqQsZqm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv(\"https://afterwork.ai/ds/e/healthcare_jvoit.csv\")\n",
        "\n",
        "# Preview the dataset\n",
        "df.head()"
      ],
      "metadata": {
        "id": "slXFuA03myXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group the data by Gender and calculate the average Age for each group\n",
        "grouped_data = df.groupby('Gender')['Age'].mean()\n",
        "\n",
        "# Display the grouped data\n",
        "grouped_data"
      ],
      "metadata": {
        "id": "i1u6xjDwslCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Challenge"
      ],
      "metadata": {
        "id": "4KCjOt51myXV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Group the healthcare dataset from the URL: https://afterwork.ai/ds/ch/healthcare_u7ep3.csv based on 'Gender' and calculate the average 'Income' for each group."
      ],
      "metadata": {
        "id": "rwWkWRaNsn1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv(\"https://afterwork.ai/ds/ch/healthcare_u7ep3.csv\")\n",
        "\n",
        "# Grouping based on Gender and calculating average Income\n",
        "# Write your code here\n",
        "\n",
        "# Display the average Income for each group\n",
        "# Write your code here\n"
      ],
      "metadata": {
        "id": "8viaMrc5myXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Introduction to NumPy"
      ],
      "metadata": {
        "id": "pHO2Bh6qauQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import NumPy to perform scientific computations\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "q2ky1jaZuPzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.1 Creating Numpy Arrays"
      ],
      "metadata": {
        "id": "BbayVloVswGR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Storing values in Numpy arrays allows us to efficiently work with large datasets and perform mathematical operations on them. Numpy arrays are similar to lists in Python, but they offer better performance and functionality for numerical computations.\n",
        "\n"
      ],
      "metadata": {
        "id": "M4HkjT0LultP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating two arrays of different shapes\n",
        "sales_data = np.array([100, 200, 300, 400])\n",
        "sales_target = np.array([500])\n",
        "\n",
        "# Print the sales data and sales target arrays\n",
        "print(sales_data)\n",
        "print(sales_target)"
      ],
      "metadata": {
        "id": "REdY-P5NufzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a dataset into a numpy array\n",
        "data = np.genfromtxt('https://afterwork.ai/ds/e/sales_iplgo.csv', delimiter=',', dtype=None, encoding='utf-8')\n",
        "\n",
        "# Print the data array\n",
        "print(data)"
      ],
      "metadata": {
        "id": "oLEvj4xFswGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Challenge"
      ],
      "metadata": {
        "id": "BOGL5JQUswGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a Numpy array from the dataset located at https://afterwork.ai/ds/ch/sales_vrka5.csv.\n"
      ],
      "metadata": {
        "id": "3KuR25-nu9am"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset into a numpy array\n",
        "# Write your code here\n",
        "\n",
        "\n",
        "# Print the sales array\n",
        "# Write your code here\n"
      ],
      "metadata": {
        "id": "S_lhUiS0swG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.2 Accessing Array Elements"
      ],
      "metadata": {
        "id": "VyBAsIxItFtc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accessing array elements in Numpy allows us to retrieve specific values stored in the array. This is important for performing operations on specific elements within the array.\n",
        "\n"
      ],
      "metadata": {
        "id": "NLdMqk_WvV2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and display the dataset\n",
        "data = np.genfromtxt('https://afterwork.ai/ds/e/sales_jq035.csv',\n",
        "                     delimiter=',',\n",
        "                     dtype=None,\n",
        "                     encoding='utf-8')\n",
        "data"
      ],
      "metadata": {
        "id": "xbDr9Th_tFto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accessing the 'Price' column\n",
        "prices = data[:, 2]\n",
        "print(prices)\n",
        "\n",
        "# Accessing the 'Quantity' column\n",
        "quantities = data[:, 3]\n",
        "print(quantities)\n",
        "\n",
        "# Accessing the 'Sales' column\n",
        "sales = data[:, 4]\n",
        "print(sales)"
      ],
      "metadata": {
        "id": "Rs17aKCbzJtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.3 Boolean Indexing"
      ],
      "metadata": {
        "id": "azyMjL0ft40O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boolean indexing in Numpy allows us to select elements from an array based on a condition. This is done by passing a boolean array as an index to another array, where only the elements corresponding to True values in the boolean array are selected.\n",
        "\n"
      ],
      "metadata": {
        "id": "lx4a2rUE1sBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "data = np.genfromtxt('https://afterwork.ai/ds/e/sales_5c3gk.csv',\n",
        "                     delimiter=',',\n",
        "                     names=True,\n",
        "                     dtype=None,\n",
        "                     encoding='utf-8')\n",
        "\n",
        "# Preview the dataset\n",
        "print(data)"
      ],
      "metadata": {
        "id": "0iflQgzAt40a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a boolean array based on a condition\n",
        "condition = data['Income'] > 60000\n",
        "condition"
      ],
      "metadata": {
        "id": "0bKuh5uD1S5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use boolean indexing to select elements based on the condition\n",
        "selected_data = data[condition]\n",
        "\n",
        "print(selected_data)"
      ],
      "metadata": {
        "id": "rPNVrCYk3nmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.4 Aggregate Functions"
      ],
      "metadata": {
        "id": "NrngVowztrDc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aggregation functions in Numpy allow us to perform mathematical operations on arrays to summarize or combine data. These functions are essential for calculating statistics, such as mean, median, sum, min, and max, on large datasets efficiently.\n",
        "\n"
      ],
      "metadata": {
        "id": "P3a2rRr6wUga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "data = np.genfromtxt('https://afterwork.ai/ds/e/sales_wzrb3.csv',\n",
        "                     delimiter=',',\n",
        "                     dtype='float',\n",
        "                     names=True,\n",
        "                     encoding='utf-8')\n",
        "# Preview the data\n",
        "data"
      ],
      "metadata": {
        "id": "O_i-VL-5trDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the total sales quantity\n",
        "total_sales_quantity = np.sum(data['Sold_Quantity'])\n",
        "\n",
        "# Calculate the average price\n",
        "average_price = np.mean(data['Price'])\n",
        "\n",
        "# Calculate the maximum price\n",
        "max_price = np.max(data['Price'])\n",
        "\n",
        "# Calculate the minimum price\n",
        "min_price = np.min(data['Price'])\n",
        "\n",
        "print(\"Total Sales Quantity:\", total_sales_quantity)\n",
        "print(\"Average Price:\", average_price)\n",
        "print(\"Max Price:\", max_price)\n",
        "print(\"Min Price:\", min_price)"
      ],
      "metadata": {
        "id": "_VGlnXA95O55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Challenge"
      ],
      "metadata": {
        "id": "qXMiII5EtrDq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate the total sales amount for the given dataset from the URL: https://afterwork.ai/ds/ch/sales_hu0g1.csv using Numpy aggregation functions. Remember to use the sum() function."
      ],
      "metadata": {
        "id": "YKwzaaEL6F0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code here\n"
      ],
      "metadata": {
        "id": "5oIsEAqytrDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Scientific Computing & Quantitative Methods"
      ],
      "metadata": {
        "id": "mAmlMPf2Z0wj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Basic Probability and Statistics"
      ],
      "metadata": {
        "id": "I68qM-lFa0J7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1.1 Probability Basics"
      ],
      "metadata": {
        "id": "ym_QIjzY-HX5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Probability basics in statistics refer to the likelihood of an event occurring, expressed as a number between 0 and 1. Understanding probability is crucial in data science as it helps us make informed decisions based on data. We use probability to quantify uncertainty and make predictions about future outcomes. For example, we can use probability to determine the likelihood of a customer making a purchase on our website, or the chances of a student passing an exam."
      ],
      "metadata": {
        "id": "phcxTeq--bUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the sample space\n",
        "sample_space = ['Heads', 'Tails']\n",
        "\n",
        "# Calculate the probability of getting Heads\n",
        "favorable_outcomes = 1\n",
        "total_outcomes = 2\n",
        "probability_heads = favorable_outcomes / total_outcomes\n",
        "\n",
        "print(\"Probability of getting Heads:\", probability_heads)"
      ],
      "metadata": {
        "id": "5RdLkXJQZ3E9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Challenge"
      ],
      "metadata": {
        "id": "KHvuOLaE-fsp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Calculate the probability of rolling a prime number on a fair six-sided die\n",
        "Define the sample space as the set of numbers {1, 2, 3, 4, 5, 6}.\n",
        "* Identify the favorable outcomes (prime numbers) and calculate the probability by dividing the number of favorable outcomes by the total number of outcomes."
      ],
      "metadata": {
        "id": "1B6ONne--jFW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the sample space\n",
        "sample_space = [1, 2, 3, 4, 5, 6]\n",
        "\n",
        "# Calculate the probability of rolling a prime number\n",
        "prime_numbers = [2, 3, 5]\n",
        "# Write your code here\n"
      ],
      "metadata": {
        "id": "vOXaDS3L-lqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1.2 Descriptive Statistics"
      ],
      "metadata": {
        "id": "-7UhaqNF-peI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Descriptive statistics in probability and statistics is the process of summarizing and describing the characteristics of a dataset. We use descriptive statistics to understand the basic features of the data, such as mean, median, mode, standard deviation, and range. This helps us to gain insights into the central tendency, dispersion, and shape of the data distribution."
      ],
      "metadata": {
        "id": "Imh7oxxa-y_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset into a Pandas DataFrame\n",
        "df = pd.read_csv(\"https://afterwork.ai/ds/e/sales_gidrs.csv\")\n",
        "\n",
        "# Display descriptive statistics\n",
        "print(df.describe())"
      ],
      "metadata": {
        "id": "RuqS3yRs-z_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1.3 Central Tendency Measures"
      ],
      "metadata": {
        "id": "NIHL_Zo__Bdk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Central tendency measures are statistical measures that represent the center or average of a data set. The most common central tendency measures are mean, median, and mode. These measures help us understand the typical value or central value of a dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "6C2P0BYH_Bdv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv(\"https://afterwork.ai/ds/e/sales_dzt4w.csv\")\n",
        "\n",
        "# Calculate mean, median, and mode\n",
        "mean = df['Sales Amount'].mean()\n",
        "median = df['Sales Amount'].median()\n",
        "mode = df['Sales Amount'].mode()[0]\n",
        "\n",
        "print(\"Mean:\", mean)\n",
        "print(\"Median:\", median)\n",
        "print(\"Mode:\", mode)"
      ],
      "metadata": {
        "id": "ylxrIohW_Bdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Challenge"
      ],
      "metadata": {
        "id": "yMpFRP8m_Bdx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate the mean, median, and mode of the Sales data from the dataset located at https://afterwork.ai/ds/ch/sales_u7eai.csv. Remember to use Python built-in functions such as mean(), median(), and mode()."
      ],
      "metadata": {
        "id": "R8nCbT2J_Bdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv(\"https://afterwork.ai/ds/ch/sales_u7eai.csv\")\n",
        "\n",
        "# Calculate mean, median, and mode\n",
        "mean = df['Sales'].mean()\n",
        "# Write your code here\n"
      ],
      "metadata": {
        "id": "lW_DJaEG_Bdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1.4 Variability Measures"
      ],
      "metadata": {
        "id": "C74nBKlL_Bx6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variability measures in data analysis refer to the statistical metrics that quantify the spread or dispersion of data points in a dataset. These measures provide insights into the diversity and distribution of the data, helping us understand the range of values and how they are distributed around the central tendency."
      ],
      "metadata": {
        "id": "eLAiXBZh_Bx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv(\"https://afterwork.ai/ds/e/sales_p2w03.csv\")\n",
        "\n",
        "# Calculate the variability measures\n",
        "sales_mean = data['Sales'].mean()\n",
        "sales_std = data['Sales'].std()\n",
        "sales_range = data['Sales'].max() - data['Sales'].min()\n",
        "\n",
        "print(sales_mean, sales_std, sales_range)"
      ],
      "metadata": {
        "id": "kZ7HGpF7_Bx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Challenge"
      ],
      "metadata": {
        "id": "F_y4ty53_Bx8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate the standard deviation of the Sales data in the dataset from the URL: https://afterwork.ai/ds/ch/sales_ngx4f.csv. Remember that standard deviation is a measure of the dispersion of data points around the mean."
      ],
      "metadata": {
        "id": "iPi0ZvVS_Bx8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv(\"https://afterwork.ai/ds/ch/sales_ngx4f.csv\")\n",
        "\n",
        "# Calculate the standard deviation of the Sales data\n",
        "# Write your code here\n"
      ],
      "metadata": {
        "id": "01dDDhgp_Bx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1.5 Sampling Methods"
      ],
      "metadata": {
        "id": "6vCykE4o_B-P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sampling methods in statistics refer to the techniques used to select a subset of individuals or items from a larger population. This subset, known as a sample, is then used to make inferences or generalizations about the population as a whole. Sampling methods are crucial in statistical inference and hypothesis testing as they help us draw conclusions about a population based on limited data.\n",
        "\n"
      ],
      "metadata": {
        "id": "G2JRQug4_B-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv(\"https://afterwork.ai/ds/e/sales_cya32.csv\")\n",
        "\n",
        "# Display the first 5 rows of the dataset\n",
        "df.head()"
      ],
      "metadata": {
        "id": "c6qnlEAp_B-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple random sampling\n",
        "sample = df.sample(n=3, random_state=1)\n",
        "sample"
      ],
      "metadata": {
        "id": "vXP-uGju_-R3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Challenge"
      ],
      "metadata": {
        "id": "8QpAV73G_B-Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the dataset from the URL: https://afterwork.ai/ds/ch/sales_jhrz6.csv, write a Python program to randomly select a sample of 5 items from the 'Product' column. Make sure to set the 'random_state' parameter to ensure reproducibility."
      ],
      "metadata": {
        "id": "gaGGvzZu_B-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv(\"https://afterwork.ai/ds/ch/sales_jhrz6.csv\")\n",
        "\n",
        "# Display the first 5 rows of the dataset\n",
        "print(df.head())\n",
        "\n",
        "# Simple random sampling\n",
        "# Write your code here\n"
      ],
      "metadata": {
        "id": "yo4qZ1SG_B-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1.6 Creating Histograms and Box Plots"
      ],
      "metadata": {
        "id": "EMFGz1GtAcjf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Matplotlib and Seaborn for data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "kVPHdwG2A7VZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating histograms and box plots in data visualization allows us to visually represent the distribution of data and identify patterns or outliers. Histograms display the frequency of data within specified intervals, while box plots show the distribution of data and identify any outliers or extreme values.\n",
        "\n"
      ],
      "metadata": {
        "id": "KJBgCVdzAcjg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv(\"https://afterwork.ai/ds/e/sales_6m7ad.csv\")\n",
        "\n",
        "# Preview the data\n",
        "data.head()"
      ],
      "metadata": {
        "id": "1zOrAFeNAcjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a histogram\n",
        "sns.histplot(data['Sales Amount'])\n",
        "plt.title('Histogram of Sales Amount')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "--0xmO6mAruk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a box plot\n",
        "sns.boxplot(x=data['Sales Amount'])\n",
        "plt.title('Box Plot of Sales Amount')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wjAZNevcBxA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Linear Regression"
      ],
      "metadata": {
        "id": "NbHvUz0ca46X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.1 The Linear Regression Model"
      ],
      "metadata": {
        "id": "Ban4LNR3HwhZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear regression models take into account a set of data points to create a line that best fits the relationship between the variables. This model is important in analyzing and predicting trends in data."
      ],
      "metadata": {
        "id": "rbt3B7R4KAcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Data Importation and Exploration\n",
        "data = pd.read_csv(\"https://afterwork.ai/ds/e/sales_bgezf.csv\")\n",
        "data.head()"
      ],
      "metadata": {
        "id": "2yMlk2Jsa7f7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Data Preparation\n",
        "X = data[['Expenses', 'Marketing']]\n",
        "y = data['Sales']\n",
        "\n",
        "# Step 3: Model Training and Evaluation\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "print(rmse)"
      ],
      "metadata": {
        "id": "0ad5WOhrGoUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Making Predictions\n",
        "new_data = pd.DataFrame({'Expenses': [40000, 50000], 'Marketing': [2000, 2500]})\n",
        "predictions = model.predict(new_data)\n",
        "print(predictions)"
      ],
      "metadata": {
        "id": "HG4wGeiWGPDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Machine Learning Fundamentals"
      ],
      "metadata": {
        "id": "Np9QNp4nZ3dy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 Regression"
      ],
      "metadata": {
        "id": "fc1zTNv_a-ti"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regression techniques involve analyzing data to understand the relationship between variables and make predictions based on that relationship. We will take into account the following information to build a regression model.\n",
        "\n",
        "Regression techniques are important because they allow us to identify patterns in data, make predictions, and understand the impact of variables on an outcome. By using regression, we can uncover insights that help in decision-making, forecasting, and understanding complex relationships.\n",
        "\n",
        "To apply regression techniques, follow these steps:\n",
        "* Collect and organize the data that includes the variables of interest.\n",
        "* Choose the appropriate regression model based on the type of data and the research question.\n",
        "* Split the data into training and testing sets to evaluate the model's performance.\n",
        "* Fit the regression model to the training data and assess its accuracy using statistical measures.\n",
        "* Use the model to make predictions on new data and evaluate its performance."
      ],
      "metadata": {
        "id": "Hu30XqqGQGtC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Data Importation and Exploration\n",
        "data = pd.read_csv(\"https://afterwork.ai/ds/e/sales_yfgk6.csv\")\n",
        "\n",
        "# Step 2: Data Preparation\n",
        "X = data[['Price', 'Quantity', 'Profit']]\n",
        "y = data['Sales']\n",
        "\n",
        "# Step 3: Model Training and Evaluation\n",
        "# Splitting the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Instantiation of models\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "svr = SVR()\n",
        "dt = DecisionTreeRegressor()\n",
        "knn = KNeighborsRegressor()\n",
        "rf = RandomForestRegressor()\n",
        "\n",
        "# Training the models\n",
        "svr.fit(X_train, y_train)\n",
        "dt.fit(X_train, y_train)\n",
        "knn.fit(X_train, y_train)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluating the models\n",
        "svr_rmse = np.sqrt(mean_squared_error(y_test, svr.predict(X_test)))\n",
        "dt_rmse = np.sqrt(mean_squared_error(y_test, dt.predict(X_test)))\n",
        "knn_rmse = np.sqrt(mean_squared_error(y_test, knn.predict(X_test)))\n",
        "rf_rmse = np.sqrt(mean_squared_error(y_test, rf.predict(X_test)))\n",
        "\n",
        "# Displaying the RMSEs\n",
        "print(\"SVR RMSE:\", svr_rmse)\n",
        "print(\"Decision Tree RMSE:\", dt_rmse)\n",
        "print(\"KNN RMSE:\", knn_rmse)\n",
        "print(\"Random Forest RMSE:\", rf_rmse)"
      ],
      "metadata": {
        "id": "-KtR3HOCZ6JU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 Classification"
      ],
      "metadata": {
        "id": "EOnALrXa5PBl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classification techniques take into account the following information: Classifying data involves organizing and categorizing data based on specific criteria. This helps in understanding patterns, making predictions, and gaining insights from the data."
      ],
      "metadata": {
        "id": "-ZZeCKOJAfEe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJZKziu743Mb"
      },
      "outputs": [],
      "source": [
        "# Import the Pandas library for data manipulation\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load and preview the data\n",
        "\n",
        "# Import the dataset\n",
        "data = pd.read_csv(\"https://afterwork.ai/ds/e/healthcare_and_pharmaceuticals_d982y.csv\")\n",
        "\n",
        "# Preview the dataset\n",
        "data.head()"
      ],
      "metadata": {
        "id": "ZJVELx0v5bS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display statistical information\n",
        "data.describe()"
      ],
      "metadata": {
        "id": "9ax8K53U5ENA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Clean and Pre-process the data\n",
        "data['Gender'] = data['Gender'].map({'Male': 0, 'Female': 1})\n",
        "data['Cholesterol'] = data['Cholesterol'].map({'Normal': 0, 'High': 1})\n",
        "data['Diabetes'] = data['Diabetes'].map({'No': 0, 'Yes': 1})\n",
        "data['Smoker'] = data['Smoker'].map({'No': 0, 'Yes': 1})\n",
        "data['Heart_Disease'] = data['Heart_Disease'].map({'No': 0, 'Yes': 1})\n",
        "data[['Systolic_BP', 'Diastolic_BP']] = data['Blood_Pressure'].str.split('/', expand=True).astype(int)\n",
        "data.drop(['Blood_Pressure', 'Patient_ID'], axis=1, inplace=True)\n",
        "\n",
        "# Drop records with missing values\n",
        "data.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "xUGQJuwB5oZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Split and Train the model\n",
        "\n",
        "# Separate features and target variables\n",
        "X = data[['Age', 'Gender', 'Weight', 'Height', 'Cholesterol', 'Diabetes', 'Smoker']]\n",
        "y = data['Heart_Disease']\n",
        "\n",
        "# Split the features and target variables into train and test variables\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "kwznOxmA542r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import machine learning algorithms\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Instantiate the models\n",
        "log_model = LogisticRegression()\n",
        "naive_model = GaussianNB()\n",
        "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
        "decision_model = DecisionTreeClassifier()\n",
        "random_model = RandomForestClassifier()\n",
        "\n",
        "# Traing the models\n",
        "log_model.fit(X_train, y_train)\n",
        "naive_model.fit(X_train, y_train)\n",
        "knn_model.fit(X_train, y_train)\n",
        "decision_model.fit(X_train, y_train)\n",
        "random_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "MnXnxn7G4Z45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Evaluate the models\n",
        "log_y_pred = log_model.predict(X_test)\n",
        "naive_y_pred = naive_model.predict(X_test)\n",
        "knn_y_pred = knn_model.predict(X_test)\n",
        "decision_y_pred = decision_model.predict(X_test)\n",
        "random_y_pred = random_model.predict(X_test)\n",
        "\n",
        "# Determine the models' accuracy scores\n",
        "from sklearn.metrics import accuracy_score\n",
        "log_accuracy = accuracy_score(y_test, log_y_pred)\n",
        "naive_accuracy = accuracy_score(y_test, naive_y_pred)\n",
        "knn_accuracy = accuracy_score(y_test, knn_y_pred)\n",
        "decision_accuracy = accuracy_score(y_test, decision_y_pred)\n",
        "random_accuracy = accuracy_score(y_test, random_y_pred)\n",
        "\n",
        "# Print the models' accuracy scores\n",
        "print(\"Logistic Regression Accuracy:\", log_accuracy)\n",
        "print(\"Naive Bayes Accuracy:\", naive_accuracy)\n",
        "print(\"K-Nearest Neighbors Accuracy:\", naive_accuracy)\n",
        "print(\"Decision Tree Accuracy:\", decision_accuracy)\n",
        "print(\"Random Forest Accuracy:\", random_accuracy)"
      ],
      "metadata": {
        "id": "TNyvki_M4cH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Make predictions with new pre-processed data\n",
        "new_data = pd.DataFrame({'Age': [50],\n",
        "                         'Gender': [0],\n",
        "                         'Weight': [75],\n",
        "                         'Height': [170],\n",
        "                         'Cholesterol': [1],\n",
        "                         'Diabetes': [0],\n",
        "                         'Smoker': [1]})\n",
        "\n",
        "# Display the new data\n",
        "new_data"
      ],
      "metadata": {
        "id": "xBaBIU7v-X4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the models to make the prediction for the new data\n",
        "log_prediction = log_model.predict(new_data)\n",
        "naive_prediction = naive_model.predict(new_data)\n",
        "knn_prediction = knn_model.predict(new_data)\n",
        "decision_prediction = decision_model.predict(new_data)\n",
        "random_prediction = random_model.predict(new_data)\n",
        "\n",
        "# Display and compare the predictions\n",
        "print(\"Logistic Predicted Heart Disease:\", log_prediction)\n",
        "print(\"Naive Bayes Predicted Heart Disease:\", naive_prediction)\n",
        "print(\"KNN Predicted Heart Disease:\", knn_prediction)\n",
        "print(\"Decision Tree Predicted Heart Disease:\", decision_prediction)\n",
        "print(\"Random Forest Predicted Heart Disease:\", random_prediction)"
      ],
      "metadata": {
        "id": "zx724wdm-nvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Challenge"
      ],
      "metadata": {
        "id": "irSK1qAU7FRX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build a Naive Bayes classification model using the healthcare and pharmaceutical dataset from the URL: https://afterwork.ai/ds/ch/healthcare_and_pharmaceuticals_1j9a.csv. Remember to preprocess the data by encoding categorical variables, splitting the data into training and testing sets, and scaling features. Train the Naive Bayes model on the training data, make predictions on the testing data, and evaluate the model's performance using the accuracy metric."
      ],
      "metadata": {
        "id": "nEa-zoQyCEa_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load and preview the data\n",
        "data = pd.read_csv(\"https://afterwork.ai/ds/ch/healthcare_and_pharmaceuticals_1j9a.csv\")\n",
        "data.head()"
      ],
      "metadata": {
        "id": "BUxQFGbu7EoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display statistical information\n",
        "data.describe()"
      ],
      "metadata": {
        "id": "2zPguSPp8vFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Clean and Pre-process the data\n",
        "data['Gender'] = data['Gender'].map({'Male': 0, 'Female': 1})\n",
        "data['Cholesterol_Level'] = data['Cholesterol_Level'].map({'Normal': 0, 'High': 1})\n",
        "data['Diabetes'] = data['Diabetes'].map({'No': 0, 'Yes': 1})\n",
        "data['Blood_Pressure'] = data['Blood_Pressure'].map({'Normal': 0, 'High': 1})\n",
        "data['Hypertension'] = data['Hypertension'].map({'No': 0, 'Yes': 1})\n",
        "data['Outcome'] = data['Outcome'].map({'Positive': 0, 'Negative': 1})\n",
        "data.drop(['ID', 'Medication', 'Patient_Name'], axis=1, inplace=True)\n",
        "data.dropna(inplace=True)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "QlSj2JD27LXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and taraget\n",
        "X = data.drop('Outcome', axis=1)\n",
        "y = data['Outcome']"
      ],
      "metadata": {
        "id": "vGZ4Ngh47Wbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Split and Train the model\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Write your code here"
      ],
      "metadata": {
        "id": "MigRCiYT7MzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Evaluate the Model\n",
        "# Write your code here"
      ],
      "metadata": {
        "id": "MM1JkW3b7OVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Make predictions\n",
        "new_data = pd.DataFrame({'Age': [40], 'Gender': [1], 'Blood_Pressure': [1], 'Cholesterol_Level': [1], 'Diabetes': [1], 'Hypertension': [1]})\n",
        "\n",
        "# Write your code here\n",
        "\n",
        "print(\"Prediction:\", prediction)"
      ],
      "metadata": {
        "id": "xKwJKJpqAKcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Advanced Machine Learning"
      ],
      "metadata": {
        "id": "-9MCIESwZ7qP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1. Clustering"
      ],
      "metadata": {
        "id": "J6QRaamXgnUu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clustering with K-Means is a popular unsupervised learning technique used to group similar data points together. The goal of K-Means clustering is to partition data into K clusters where each data point belongs to the cluster with the nearest mean. This technique is commonly used for customer segmentation, anomaly detection, and image compression.\n",
        "\n"
      ],
      "metadata": {
        "id": "cIrOasjvUf9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement the K-Means clustering algorithm using the dataset from the URL: https://afterwork.ai/ds/ch/healthcare_and_pharmaceuticals_j59n.csv."
      ],
      "metadata": {
        "id": "rRsCgigQwuSo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load and preview the data\n",
        "data = pd.read_csv(\"https://afterwork.ai/ds/e/healthcare_and_pharmaceuticals_45e9n.csv\")\n",
        "data.head()"
      ],
      "metadata": {
        "id": "hKpfPw6ggzbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Clean and Pre-process the data\n",
        "data['Gender'] = data['Gender'].map({'Male': 0, 'Female': 1})\n",
        "data[['Systolic_BP', 'Diastolic_BP']] = data['Blood_Pressure'].str.split('/', expand=True).astype(int)\n",
        "data['Cholesterol'] = data['Cholesterol'].map({'Normal': 0, 'High': 1})\n",
        "data.drop(['Patient_ID', 'Blood_Pressure', 'Medication'], axis=1, inplace=True)\n",
        "data.dropna(inplace=True)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "uohxcCFNg0oM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Split and Train the model\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# By setting n_init=10, we specify the number of times\n",
        "# KMeans will be run with different centroid seeds.\n",
        "kmeans = KMeans(n_clusters=3, n_init='auto')\n",
        "kmeans.fit(data)"
      ],
      "metadata": {
        "id": "Q3UKf8zNg13X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Evaluate the Model\n",
        "data['Cluster'] = kmeans.labels_\n",
        "\n",
        "# Display some records to check the assigned clustering groups\n",
        "data.sample(10)"
      ],
      "metadata": {
        "id": "UR9ChdqOg3Nb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We check for optimal no. of k\n",
        "#\n",
        "# We check the optimal values of k using the elbow method.\n",
        "# We first use the KMeans algorithm for different values of k (say K = 10 to 1)\n",
        "# and plot the K values against SSE (Sum of squared errors).\n",
        "# We then select the value of k for the elbow point as shown in the figure.\n",
        "#\n",
        "import matplotlib.pyplot as plt\n",
        "Error = []\n",
        "for i in range(1, 11):\n",
        "    kmeans = KMeans(n_clusters = i, n_init='auto').fit(X)\n",
        "    Error.append(kmeans.inertia_)\n",
        "plt.plot(range(1, 11), Error, 'bx-')\n",
        "plt.title('Elbow method')\n",
        "plt.xlabel('No of clusters')\n",
        "plt.ylabel('Error')\n",
        "plt.grid(True);"
      ],
      "metadata": {
        "id": "duj9TfkLg4b0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preview the first cluster\n",
        "first_cluster = data[data['Cluster'].isin([0])]\n",
        "first_cluster.head()"
      ],
      "metadata": {
        "id": "CCyP2OObo3E7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preview the second cluster\n",
        "second_cluster = data[data['Cluster'].isin([1])]\n",
        "second_cluster.head()"
      ],
      "metadata": {
        "id": "sEjk_rzmo4dA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2 Dimensionality Reduction"
      ],
      "metadata": {
        "id": "_0DqBhKMbH6-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dimensionality Reduction with PCA is a technique used to reduce the number of features in a dataset while preserving as much variance as possible. By transforming the data into a lower-dimensional space, we can simplify the data representation, reduce computational complexity, and remove noise or irrelevant information.\n",
        "\n",
        "This concept is important because it can help improve the performance of machine learning models by reducing overfitting, speeding up training times, and enhancing interpretability. Additionally, dimensionality reduction can aid in data visualization, making it easier to explore and understand complex datasets."
      ],
      "metadata": {
        "id": "4Dxpu_C0WwfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import and preview the dataset\n",
        "data = pd.read_csv(\"https://afterwork.ai/ds/e/sales_lncd4.csv\")\n",
        "data.head()"
      ],
      "metadata": {
        "id": "XY6a1MzPbH6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Data Preparation\n",
        "X = data.drop(['Region', 'Product Type', 'Quarter', 'Year'], axis=1)\n",
        "\n",
        "# Step 3: Model Training and Evaluation\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=3)\n",
        "X_pca = pca.fit_transform(X)\n",
        "\n",
        "# Step 4: Making Predictions\n",
        "print(X_pca)"
      ],
      "metadata": {
        "id": "BMXckcUsW7FN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Challenge"
      ],
      "metadata": {
        "id": "yR9vfGGfXLnh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform dimensionality reduction using PCA on the sales dataset from the URL: https://afterwork.ai/ds/ch/sales_fv89h.csv. Remember to first load the dataset, preprocess the data (if necessary), and then apply PCA to reduce the number of features while preserving variance.\n"
      ],
      "metadata": {
        "id": "-r-mfTyWXN9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Step 1: Data Importation and Exploration\n",
        "data = pd.read_csv(\"https://afterwork.ai/ds/ch/sales_fv89h.csv\")\n",
        "data.head()"
      ],
      "metadata": {
        "id": "Y9-xd2-kXO8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Data Preparation\n",
        "X = data.drop(['Product', 'Salesperson', 'Region', 'Year'], axis=1)\n",
        "\n",
        "# Step 3: Model Training and Evaluation\n",
        "# Write your code here\n",
        "\n",
        "# Step 4: Making Predictions\n",
        "# Write your code here"
      ],
      "metadata": {
        "id": "K669HpN0X5yG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.3 Pyspark"
      ],
      "metadata": {
        "id": "eSsMc_WibILr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading data into DataFrames in PySpark allows us to work with large datasets efficiently. We can read data from various sources such as CSV, JSON, Parquet, etc., and perform data manipulation and analysis on it. In addition, grouping and aggregating data in PySpark allows us to combine and summarize data based on certain criteria.\n",
        "\n"
      ],
      "metadata": {
        "id": "LI8LWyu9jtJd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the PySpark library for big data preprocessing\n",
        "!pip install pyspark"
      ],
      "metadata": {
        "id": "UUASt5axg-0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create a SparkSession\n",
        "spark = SparkSession.builder.appName(\"SalesAnalysis\").getOrCreate()\n",
        "\n",
        "# Load the dataset from the CSV file: https://afterwork.ai/ds/e/sales_okc8i.csv\n",
        "df = spark.read.csv(\"sales_okc8i.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Explore the dataset\n",
        "print(\"First 5 rows of the dataset:\")\n",
        "df.show(5)"
      ],
      "metadata": {
        "id": "f8XOVMx3bILs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the schema of the dataset\n",
        "print(\"Schema of the dataset:\")\n",
        "df.printSchema()"
      ],
      "metadata": {
        "id": "UsbHLtThhVIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform further analysis\n",
        "print(\"Aggregated data by Region:\")\n",
        "df_grouped = df.groupBy(\"Region\").agg({\"Price\": \"sum\", \"Quantity\": \"sum\"})\n",
        "df_grouped.show()"
      ],
      "metadata": {
        "id": "bs29d5rkijJl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}